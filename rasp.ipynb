{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/datamining/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:124: DeprecationWarning: update is deprecated. Use replace_one, update_one or update_many instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n': 0, 'nModified': 0, 'ok': 1.0, 'updatedExisting': False}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import join\n",
    "from PIL import Image\n",
    "from time import strftime\n",
    "import imutils\n",
    "import cv2\n",
    "import pickle\n",
    "import base64\n",
    "from pymongo import MongoClient\n",
    "\n",
    "path1 = \"raw\"\n",
    "path2 = \"resize\"\n",
    "path3 = \"schannel\"\n",
    "path4 = \"acne\"\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')\n",
    "\n",
    "files = listdir(path1)\n",
    "files.sort()\n",
    "\n",
    "for f in files:\n",
    "    file_path1 = join(path1, f)\n",
    "    file_path2 = join(path2, f)\n",
    "\n",
    "    img = cv2.imread(file_path1)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor = 1.16, minNeighbors = 5, minSize = (25,25))\n",
    "    for (x, y, w, h) in faces:\n",
    "        roi_color = img[y : y + h, x : x + w]\n",
    "\n",
    "    cut_img = img[y : y + h, x : x + w]\n",
    "    resize_img = cv2.resize(cut_img, (300,300), interpolation = cv2.INTER_AREA)\n",
    "    cv2.imwrite(file_path2, resize_img)\n",
    "\n",
    "#please check pictures in resize folder\n",
    "\n",
    "for x in files:\n",
    "    file_path2 = join(path2, x)\n",
    "    file_path3 = join(path3, x)\n",
    "    hsv_img = cv2.imread(file_path2)\n",
    "    hsv_img = cv2.cvtColor(hsv_img, cv2.COLOR_BGR2HSV)\n",
    "    cv2.imwrite(file_path3, hsv_img[:,:,1])\n",
    "\n",
    "for z in files:\n",
    "    file_path2 = join(path2, z)\n",
    "    file_path4 = join(path4, z)\n",
    "    img = Image.open(file_path2)\n",
    "    width = img.size[0]\n",
    "    height = img.size[1]\n",
    "    \n",
    "    leftCheek = ( width / 6, height / 2, width / 3, height / 3 * 2)\n",
    "    cropped_img = img.crop(leftCheek)\n",
    "    \n",
    "    rightCheek = ( width / 3 * 2, height / 2, width / 6 * 5, height / 3 * 2)\n",
    "    cropped_img2 = img.crop(rightCheek)\n",
    "    #Reserved picture\n",
    "    toImage = Image.new('RGB', (100, 50))\n",
    "    #Paste two pictures\n",
    "    toImage.paste(cropped_img, (0, 0))\n",
    "    toImage.paste(cropped_img2, (50, 0))\n",
    "    toImage.save(file_path4)\n",
    "\n",
    "# resize the image to a fixed size, then flatten the image into\n",
    "# a list of raw pixel intensities\n",
    "def image_to_feature_vector(image, size = (100, 50)):\n",
    "    return cv2.resize(image, size).flatten()\n",
    "\n",
    "def extract_color_histogram(image, bins = (8, 8, 8)):\n",
    "    # extract a 3D color histogram from the HSV color space using\n",
    "    # the supplied number of `bins` per channel\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, bins, [0, 180, 0, 256, 0, 256])\n",
    "\n",
    "    # handle normalizing the histogram if we are using OpenCV 2.4.X\n",
    "    if imutils.is_cv2():\n",
    "        hist = cv2.normalize(hist)\n",
    "\n",
    "    # otherwise, perform \"in place\" normalization in OpenCV 3 (I\n",
    "    # personally hate the way this is done\n",
    "    else:\n",
    "        cv2.normalize(hist, hist)\n",
    "\n",
    "    # return the flattened histogram as the feature vector\n",
    "    return hist.flatten()\n",
    "\n",
    "model_1 = pickle.load(open('20180408_final_knn_hsv_schannel.pkl', 'rb'))\n",
    "image_1 = cv2.imread('schannel/raspberry.jpg')\n",
    "hist = extract_color_histogram(image_1)\n",
    "result_1 = model_1.predict(hist.reshape(1, -1))[0]\n",
    "\n",
    "model_2 = pickle.load(open('20180408_final_knn_rgb_cheek.pkl', 'rb'))\n",
    "image_2 = cv2.imread('acne/raspberry.jpg')\n",
    "pixels = image_to_feature_vector(image_2)\n",
    "result_2 = model_2.predict(pixels.reshape(1, -1))[0]\n",
    "\n",
    "dict = {'oil': {'good': 'oil_good', 'notgood': 'oil_bad'},\n",
    "        'middle': {'good': 'middle_good', 'notgood': 'middle_bad'},\n",
    "        'dry': {'good': 'dry_good', 'notgood': 'dry_bad'}}\n",
    "\n",
    "### Client\n",
    "image = open('raw/raspberry.jpg', 'rb')\n",
    "image_64_encode = base64.b64encode(image.read())\n",
    "#image_file = open('translate.txt','wb')\n",
    "#image_file.write(image_64_encode)\n",
    "#image_file.close()\n",
    "\n",
    "data = {}\n",
    "data['face'] = result_1\n",
    "data['skin'] = result_2\n",
    "data['model'] = dict[result_1][result_2]\n",
    "data['timestamp'] = strftime('%Y%m%d_%H%M%S')\n",
    "data['z_img'] = image_64_encode.decode('utf-8')\n",
    "\n",
    "client = MongoClient(\"mongodb://35.196.140.167:27017\")\n",
    "db = client.faceai\n",
    "collect = db.project\n",
    "collect.update({'_id':\"5aca93ea1d41c80e41247a97\"}, data, upsert = False)\n",
    "\n",
    "#rethinkDB\n",
    "#conn = r.connect(host = '35.196.140.167', port = 28015)\n",
    "#try:\n",
    "#    r.db_create('faceai').run(conn)\n",
    "#except:\n",
    "#    pass\n",
    "#\n",
    "#conn.use('faceai')\n",
    "#\n",
    "#try:\n",
    "#    r.table_create('project', primary_key = \"id\").run(conn)\n",
    "#except:\n",
    "#    pass\n",
    "#\n",
    "#r.db('faceai').table('project').filter(\n",
    "#    {'id': '916bcc4a-85a4-4cac-93b7-a00f9505f073'}).update(data).run(conn)\n",
    "\n",
    "#storage_client = google.cloud.storage.Client() \n",
    "#bucket = storage_client.get_bucket('face-ai')\n",
    "#source_file_name = 'translate.txt'\n",
    "#blob = bucket.blob(os.path.basename(source_file_name))\n",
    "#blob.upload_from_filename(source_file_name)\n",
    "#print('File {} uploaded to {}.'.format(source_file_name, bucket))\n",
    "\n",
    "#!gsutil cp gs://face-ai/translate.txt ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
